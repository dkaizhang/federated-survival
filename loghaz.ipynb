{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "import warnings\n",
    "\n",
    "from load import read_csv\n",
    "\n",
    "from pycox.models import LogisticHazard\n",
    "from pycox.evaluation import EvalSurv\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "datapath = './Data/data.csv'\n",
    "data = read_csv(datapath)\n",
    "print(data.shape)\n",
    "data = data.drop(columns='PATIENTID')\n",
    "print(data.columns)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(40018, 42)\n",
      "Index(['GRADE', 'AGE', 'SEX', 'QUINTILE_2015', 'TUMOUR_COUNT', 'SACT',\n",
      "       'REGIMEN_COUNT', 'CLINICAL_TRIAL_INDICATOR',\n",
      "       'CHEMO_RADIATION_INDICATOR', 'NORMALISED_HEIGHT', 'NORMALISED_WEIGHT',\n",
      "       'DAYS_TO_FIRST_SURGERY', 'DAYS_SINCE_DIAGNOSIS', 'SITE_C70', 'SITE_C71',\n",
      "       'SITE_C72', 'SITE_D32', 'SITE_D33', 'SITE_D35', 'BENIGN_BEHAVIOUR',\n",
      "       'CREG_L0201', 'CREG_L0301', 'CREG_L0401', 'CREG_L0801', 'CREG_L0901',\n",
      "       'CREG_L1001', 'CREG_L1201', 'CREG_L1701', 'LAT_9', 'LAT_B', 'LAT_L',\n",
      "       'LAT_M', 'LAT_R', 'ETH_A', 'ETH_B', 'ETH_C', 'ETH_M', 'ETH_O', 'ETH_U',\n",
      "       'ETH_W', 'EVENT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# standardisation of features\n",
    "cols_standardise = ['GRADE', 'AGE', 'QUINTILE_2015', 'NORMALISED_HEIGHT', 'NORMALISED_WEIGHT']\n",
    "cols_minmax = ['SEX', 'TUMOUR_COUNT', 'REGIMEN_COUNT']\n",
    "cols_leave = ['SACT', 'CLINICAL_TRIAL_INDICATOR', 'CHEMO_RADIATION_INDICATOR','BENIGN_BEHAVIOUR','SITE_C70', 'SITE_C71', 'SITE_C72', 'SITE_D32','SITE_D33','SITE_D35','CREG_L0201','CREG_L0301','CREG_L0401','CREG_L0801','CREG_L0901','CREG_L1001','CREG_L1201','CREG_L1701','LAT_9','LAT_B','LAT_L','LAT_M','LAT_R','ETH_A','ETH_B','ETH_C','ETH_M','ETH_O','ETH_U','ETH_W','DAYS_TO_FIRST_SURGERY']\n",
    "\n",
    "all_cols = cols_standardise + cols_minmax + cols_leave\n",
    "\n",
    "print(len(data.columns) == len(cols_standardise + cols_minmax + cols_leave) + 2)\n",
    "\n",
    "standardise = [([col], StandardScaler()) for col in cols_standardise]\n",
    "minmax = [([col], MinMaxScaler()) for col in cols_minmax]\n",
    "leave = [(col, None) for col in cols_leave]\n",
    "\n",
    "x_mapper = DataFrameMapper(standardise + minmax + leave)\n",
    "\n",
    "# discretisation\n",
    "num_durations = 50\n",
    "labtrans = LogisticHazard.label_transform(num_durations, scheme='quantiles')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df_test = data.sample(frac=0.1)\n",
    "df_train = data.drop(df_test.index)\n",
    "df_val = df_train.sample(frac=0.1)\n",
    "df_train = df_train.drop(df_val.index)\n",
    "\n",
    "get_target = lambda df: (df['DAYS_SINCE_DIAGNOSIS'].values, df['EVENT'].values)\n",
    "y_train = labtrans.fit_transform(*get_target(df_train))\n",
    "y_val = labtrans.transform(*get_target(df_val))\n",
    "y_test = get_target(df_test)\n",
    "\n",
    "x_train = x_mapper.fit_transform(df_train).astype('float32')\n",
    "x_val = x_mapper.transform(df_val).astype('float32')\n",
    "x_test = x_mapper.transform(df_test).astype('float32')\n",
    "\n",
    "\n",
    "train = (x_train, y_train)\n",
    "val = (x_val, y_val)\n",
    "\n",
    "in_features = x_train.shape[1]\n",
    "num_nodes = [42, 42]\n",
    "out_features = labtrans.out_features\n",
    "batch_norm = True\n",
    "dropout = 0.1\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
    "model = LogisticHazard(net, tt.optim.Adam(0.001), duration_index=labtrans.cuts)\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "callbacks = [tt.cb.EarlyStopping()]\n",
    "\n",
    "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, val_data=val)\n",
    "# log = model.fit(x_train, y_train, batch_size, epochs, callbacks)\n",
    "\n",
    "surv = model.interpolate(10).predict_surv_df(x_test)\n",
    "\n",
    "ev = EvalSurv(surv, *y_test, censor_surv='km')\n",
    "print(ev.concordance_td('antolini'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 20.8630\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 7.3310\n",
      "2:\t[0s / 1s],\t\ttrain_loss: 2.8595\n",
      "3:\t[0s / 1s],\t\ttrain_loss: 2.3182\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 2.1966\n",
      "5:\t[0s / 2s],\t\ttrain_loss: 2.1605\n",
      "6:\t[0s / 2s],\t\ttrain_loss: 2.1403\n",
      "7:\t[0s / 2s],\t\ttrain_loss: 2.1325\n",
      "8:\t[0s / 3s],\t\ttrain_loss: 2.1495\n",
      "9:\t[0s / 3s],\t\ttrain_loss: 2.1232\n",
      "0.45883017168196766\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}