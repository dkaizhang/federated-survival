{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "import warnings\n",
    "\n",
    "from load import read_csv\n",
    "\n",
    "from pycox.models import LogisticHazard\n",
    "from pycox.evaluation import EvalSurv\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "datapath = './Data/data.csv'\n",
    "data = read_csv(datapath)\n",
    "print(data.shape)\n",
    "data = data.drop(columns='PATIENTID')\n",
    "print(data.columns)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(40018, 42)\n",
      "Index(['GRADE', 'AGE', 'SEX', 'QUINTILE_2015', 'TUMOUR_COUNT', 'SACT',\n",
      "       'REGIMEN_COUNT', 'CLINICAL_TRIAL_INDICATOR',\n",
      "       'CHEMO_RADIATION_INDICATOR', 'NORMALISED_HEIGHT', 'NORMALISED_WEIGHT',\n",
      "       'DAYS_TO_FIRST_SURGERY', 'DAYS_SINCE_DIAGNOSIS', 'SITE_C70', 'SITE_C71',\n",
      "       'SITE_C72', 'SITE_D32', 'SITE_D33', 'SITE_D35', 'BENIGN_BEHAVIOUR',\n",
      "       'CREG_L0201', 'CREG_L0301', 'CREG_L0401', 'CREG_L0801', 'CREG_L0901',\n",
      "       'CREG_L1001', 'CREG_L1201', 'CREG_L1701', 'LAT_9', 'LAT_B', 'LAT_L',\n",
      "       'LAT_M', 'LAT_R', 'ETH_A', 'ETH_B', 'ETH_C', 'ETH_M', 'ETH_O', 'ETH_U',\n",
      "       'ETH_W', 'EVENT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# standardisation of features\n",
    "cols_standardise = ['GRADE', 'AGE', 'QUINTILE_2015', 'NORMALISED_HEIGHT', 'NORMALISED_WEIGHT']\n",
    "cols_minmax = ['SEX', 'TUMOUR_COUNT', 'REGIMEN_COUNT']\n",
    "cols_leave = ['SACT', 'CLINICAL_TRIAL_INDICATOR', 'CHEMO_RADIATION_INDICATOR','BENIGN_BEHAVIOUR','SITE_C70', 'SITE_C71', 'SITE_C72', 'SITE_D32','SITE_D33','SITE_D35','CREG_L0201','CREG_L0301','CREG_L0401','CREG_L0801','CREG_L0901','CREG_L1001','CREG_L1201','CREG_L1701','LAT_9','LAT_B','LAT_L','LAT_M','LAT_R','ETH_A','ETH_B','ETH_C','ETH_M','ETH_O','ETH_U','ETH_W','DAYS_TO_FIRST_SURGERY']\n",
    "\n",
    "all_cols = cols_standardise + cols_minmax + cols_leave\n",
    "\n",
    "print(len(data.columns) == len(cols_standardise + cols_minmax + cols_leave) + 2)\n",
    "\n",
    "standardise = [([col], StandardScaler()) for col in cols_standardise]\n",
    "minmax = [([col], MinMaxScaler()) for col in cols_minmax]\n",
    "leave = [(col, None) for col in cols_leave]\n",
    "\n",
    "x_mapper = DataFrameMapper(standardise + minmax + leave)\n",
    "\n",
    "# discretisation\n",
    "num_durations = 50\n",
    "labtrans = LogisticHazard.label_transform(num_durations, scheme='quantiles')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df_test = data.sample(frac=0.1)\n",
    "df_train = data.drop(df_test.index)\n",
    "df_val = df_train.sample(frac=0.1)\n",
    "df_train = df_train.drop(df_val.index)\n",
    "\n",
    "get_target = lambda df: (df['DAYS_SINCE_DIAGNOSIS'].values, df['EVENT'].values)\n",
    "y_train = labtrans.fit_transform(*get_target(df_train))\n",
    "y_val = labtrans.transform(*get_target(df_val))\n",
    "y_test = get_target(df_test)\n",
    "\n",
    "x_train = x_mapper.fit_transform(df_train).astype('float32')\n",
    "x_val = x_mapper.transform(df_val).astype('float32')\n",
    "x_test = x_mapper.transform(df_test).astype('float32')\n",
    "\n",
    "\n",
    "train = (x_train, y_train)\n",
    "val = (x_val, y_val)\n",
    "\n",
    "in_features = x_train.shape[1]\n",
    "num_nodes = [168, 168, 168, 168]\n",
    "out_features = labtrans.out_features\n",
    "batch_norm = True\n",
    "dropout = 0.1\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
    "model = LogisticHazard(net, tt.optim.Adam(0.0005), duration_index=labtrans.cuts)\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "callbacks = [tt.cb.EarlyStopping()]\n",
    "\n",
    "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, val_data=val)\n",
    "# log = model.fit(x_train, y_train, batch_size, epochs, callbacks)\n",
    "\n",
    "surv = model.interpolate(10).predict_surv_df(x_test)\n",
    "\n",
    "ev = EvalSurv(surv, *y_test, censor_surv='km')\n",
    "print(ev.concordance_td('antolini'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0:\t[1s / 1s],\t\ttrain_loss: 21.7236,\tval_loss: 15.9305\n",
      "1:\t[1s / 2s],\t\ttrain_loss: 9.1735,\tval_loss: 4.2051\n",
      "2:\t[1s / 3s],\t\ttrain_loss: 3.2375,\tval_loss: 2.4347\n",
      "3:\t[1s / 4s],\t\ttrain_loss: 2.3843,\tval_loss: 2.1559\n",
      "4:\t[1s / 6s],\t\ttrain_loss: 2.2136,\tval_loss: 2.0959\n",
      "5:\t[1s / 7s],\t\ttrain_loss: 2.1575,\tval_loss: 2.0621\n",
      "6:\t[1s / 8s],\t\ttrain_loss: 2.1434,\tval_loss: 2.0540\n",
      "7:\t[1s / 9s],\t\ttrain_loss: 2.1294,\tval_loss: 2.0480\n",
      "8:\t[1s / 10s],\t\ttrain_loss: 2.1160,\tval_loss: 2.0493\n",
      "9:\t[1s / 12s],\t\ttrain_loss: 2.1115,\tval_loss: 2.0488\n",
      "10:\t[1s / 13s],\t\ttrain_loss: 2.1109,\tval_loss: 2.0440\n",
      "11:\t[1s / 14s],\t\ttrain_loss: 2.1037,\tval_loss: 2.0468\n",
      "12:\t[1s / 15s],\t\ttrain_loss: 2.1055,\tval_loss: 2.0442\n",
      "13:\t[1s / 16s],\t\ttrain_loss: 2.0971,\tval_loss: 2.0396\n",
      "14:\t[1s / 18s],\t\ttrain_loss: 2.0908,\tval_loss: 2.0378\n",
      "15:\t[1s / 19s],\t\ttrain_loss: 2.0909,\tval_loss: 2.0410\n",
      "16:\t[1s / 20s],\t\ttrain_loss: 2.0872,\tval_loss: 2.0405\n",
      "17:\t[1s / 21s],\t\ttrain_loss: 2.0877,\tval_loss: 2.0421\n",
      "18:\t[1s / 22s],\t\ttrain_loss: 2.0798,\tval_loss: 2.0391\n",
      "19:\t[1s / 24s],\t\ttrain_loss: 2.0762,\tval_loss: 2.0461\n",
      "20:\t[1s / 25s],\t\ttrain_loss: 2.0718,\tval_loss: 2.0427\n",
      "21:\t[1s / 26s],\t\ttrain_loss: 2.0702,\tval_loss: 2.0387\n",
      "22:\t[1s / 27s],\t\ttrain_loss: 2.0670,\tval_loss: 2.0347\n",
      "23:\t[1s / 28s],\t\ttrain_loss: 2.0654,\tval_loss: 2.0371\n",
      "24:\t[1s / 30s],\t\ttrain_loss: 2.0648,\tval_loss: 2.0399\n",
      "25:\t[1s / 31s],\t\ttrain_loss: 2.0688,\tval_loss: 2.0382\n",
      "26:\t[1s / 32s],\t\ttrain_loss: 2.0602,\tval_loss: 2.0420\n",
      "27:\t[1s / 33s],\t\ttrain_loss: 2.0528,\tval_loss: 2.0340\n",
      "28:\t[1s / 34s],\t\ttrain_loss: 2.0516,\tval_loss: 2.0370\n",
      "29:\t[1s / 35s],\t\ttrain_loss: 2.0494,\tval_loss: 2.0369\n",
      "30:\t[1s / 37s],\t\ttrain_loss: 2.0464,\tval_loss: 2.0351\n",
      "31:\t[1s / 38s],\t\ttrain_loss: 2.0444,\tval_loss: 2.0415\n",
      "32:\t[1s / 39s],\t\ttrain_loss: 2.0416,\tval_loss: 2.0387\n",
      "33:\t[1s / 40s],\t\ttrain_loss: 2.0396,\tval_loss: 2.0493\n",
      "34:\t[1s / 41s],\t\ttrain_loss: 2.0515,\tval_loss: 2.0417\n",
      "35:\t[1s / 43s],\t\ttrain_loss: 2.0409,\tval_loss: 2.0386\n",
      "36:\t[1s / 44s],\t\ttrain_loss: 2.0382,\tval_loss: 2.0426\n",
      "37:\t[1s / 45s],\t\ttrain_loss: 2.0363,\tval_loss: 2.0440\n",
      "0.7431857603520332\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}